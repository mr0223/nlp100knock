{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309cbab6",
   "metadata": {},
   "source": [
    "## 80. ID番号への変換\n",
    "1. ~~単語をIDに変換する辞書を作成・保存(重いため,2回目以降はセル2を実行)~~\n",
    "2. 辞書の読み込み\n",
    "3. 単語列をID列に変換する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc390a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pklファイルから読み込み\n",
    "import pickle\n",
    "\n",
    "with open('../data/ch09/name_to_id.pkl', 'rb') as tf:\n",
    "    name_to_id = pickle.load(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0b8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 与えられた単語列に対し, ID番号の列を返す関数\n",
    "# ch06ではCountVectorizerを利用したため, 今回もCountVectorizerを活用する\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def convert_words_to_ids(words):\n",
    "    '''\n",
    "    input :words(単語列)\n",
    "    output:ids(ID番号列)\n",
    "    '''\n",
    "    # analyzer: 単語列に前処理を加え, listに変換する関数\n",
    "    analyzer = CountVectorizer().build_analyzer()\n",
    "    word_list = analyzer(words)\n",
    "    \n",
    "    ids = []\n",
    "    for word in word_list:\n",
    "        if word in name_to_id:\n",
    "            ids.append(name_to_id[word])\n",
    "        else:\n",
    "            ids.append(0)  # 未知語の場合, IDを0とする\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8587b66",
   "metadata": {},
   "source": [
    "## GPU prepare\n",
    "1. 使用可能GPUの確認\n",
    "2. GPUの指定\n",
    "3. PyTorchで利用できるGPU数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8a87e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  1 13:23:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:01:00.0 Off |                  Off |\n",
      "| 30%   32C    P8    23W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    On   | 00000000:25:00.0 Off |                  Off |\n",
      "| 30%   33C    P8    14W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 30%   30C    P8    30W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    On   | 00000000:61:00.0 Off |                  Off |\n",
      "| 30%   29C    P8    27W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A6000    On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 30%   30C    P8    23W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A6000    On   | 00000000:A1:00.0 Off |                  Off |\n",
      "| 30%   28C    P8    18W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A6000    On   | 00000000:C1:00.0 Off |                  Off |\n",
      "| 30%   29C    P8    15W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A6000    On   | 00000000:E1:00.0 Off |                  Off |\n",
      "| 30%   29C    P8    18W / 300W |      5MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# 使用可能GPUの確認\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772a2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUの指定\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' #0番を使用するとき"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dafe4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# 確認\n",
    "import torch\n",
    "print(torch.cuda.device_count()) #Pytorchで使用できるGPU数を取得"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f05cde",
   "metadata": {},
   "source": [
    "## prepare\n",
    "1. 語彙数の取得\n",
    "2. 学習データの用意(ラベル)\n",
    "3. 学習データの用意(特徴量)\n",
    "4. 乱数の種を固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090f0044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 語彙数の取得(ID:0の単語はまとめて1語とする), 未知語, paddingを考慮\n",
    "vocab_size = max(name_to_id.values())+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7cfbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練・検証・評価データの用意\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ラベル: ch08の出力を利用\n",
    "Y_train = np.loadtxt('../data/ch08/Y_train.txt')\n",
    "Y_valid = np.loadtxt('../data/ch08/Y_valid.txt')\n",
    "Y_test = np.loadtxt('../data/ch08/Y_test.txt')\n",
    "\n",
    "# pytorch用に変換\n",
    "Y_train_long = torch.tensor(Y_train, dtype=torch.int64)\n",
    "Y_valid_long = torch.tensor(Y_valid, dtype=torch.int64)\n",
    "Y_test_long = torch.tensor(Y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d8d1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量: convert_words_to_ids(80)を利用\n",
    "def convert_text_to_features(fname):\n",
    "    '''\n",
    "    input :fname\n",
    "    output:features(tensor)\n",
    "    '''\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # id列(list)のリストに変換\n",
    "    ids_list = [convert_words_to_ids(line) for line in lines]\n",
    "    \n",
    "    # id列(tensor)のリストに変換\n",
    "    ids_tensor = [torch.tensor(ids, dtype=torch.int64) for ids in ids_list]\n",
    "    \n",
    "    # 最大のid+1(vocab_size-1)でパディング\n",
    "    features = torch.nn.utils.rnn.pad_sequence(ids_tensor, batch_first=True, padding_value=vocab_size-1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 特徴量抽出\n",
    "X_train_long = convert_text_to_features('../data/ch06/train.txt')\n",
    "X_valid_long = convert_text_to_features('../data/ch06/valid.txt')\n",
    "X_test_long = convert_text_to_features('../data/ch06/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "713279bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数シードの固定\n",
    "import random\n",
    "\n",
    "def fix_seed(seed):\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # Numpy\n",
    "    np.random.seed(seed)\n",
    "    # Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060692bb",
   "metadata": {},
   "source": [
    "## 83. ミニバッチ化・GPU上での学習\n",
    "1. ~~GPUに対応したRNNの定義~~\n",
    "2. GPUに対応したaccuracy計測関数の定義\n",
    "3. ~~ミニバッチ化し, GPU上で学習~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c767c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracyの計測\n",
    "def measure_loss_accuracy2(model, criterion, dataloader):\n",
    "    '''\n",
    "    input : model, criterion, dataloader\n",
    "    output: loss, accuracy\n",
    "    '''\n",
    "    running_loss = 0\n",
    "    correct_num = 0\n",
    "    device = model.device\n",
    "    batch_size = model.batch_size\n",
    "    for X, Y in dataloader:\n",
    "        # GPU上に\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        model.init_hidden()\n",
    "        predict_y = model.forward(X)\n",
    "        \n",
    "        # lossの計算\n",
    "        loss = criterion(predict_y, Y)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # accuracyの計算\n",
    "        predict_label = torch.max(predict_y, 1)[1]\n",
    "        for i in range(batch_size):\n",
    "            if predict_label[i] == Y[i]:\n",
    "                correct_num += 1\n",
    "    \n",
    "    loss_avg = running_loss/len(dataloader)\n",
    "    accuracy = correct_num/(len(dataloader)*batch_size)\n",
    "    \n",
    "    return loss_avg, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd64f93",
   "metadata": {},
   "source": [
    "## 85. 双方向RNN・多層化\n",
    "1. biRNNの定義\n",
    "2. ~~biRNNの学習~~\n",
    "3. ~~多層biRNNの学習~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38adc754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# biRNNの定義\n",
    "class biRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, batch_size, num_layers=1):\n",
    "        # 層の定義\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=vocab_size-1)\n",
    "        # biRNNに対応: bidirectional=True\n",
    "        self.birnn = nn.RNN(embedding_dim, hidden_size, num_layers=self.num_layers, batch_first=True, bidirectional=True)\n",
    "        # biRNNに対応: birnnの出力次元はrnnの次元の2倍\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "        # GPUに移す\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self = self.to(self.device)\n",
    "    \n",
    "    def init_hidden(self, batch_size=None):\n",
    "        if not batch_size:\n",
    "            batch_size = self.batch_size\n",
    "        # biRNNに対応: birnnの出力次元はrnnの次元の2倍\n",
    "        self.hidden_state = torch.zeros(self.num_layers*2, batch_size, self.hidden_size).to(self.device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        # biRNNに対応\n",
    "        x_birnn, self.hidden_state =self.birnn(x, self.hidden_state)\n",
    "        x = self.fc(x_birnn[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e3e5a",
   "metadata": {},
   "source": [
    "## 88. パラメータチューニング\n",
    "1. train, validの定義\n",
    "2. objectiveの定義\n",
    "3. optunaによるパラメータチューニング\n",
    "4. 結果表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a48c709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for X, Y in train_loader:\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        model.init_hidden()\n",
    "        predict_y = model(X)\n",
    "        loss = F.cross_entropy(predict_y, Y)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        # 更新\n",
    "        optimizer.step()\n",
    "\n",
    "def valid(model, device, valid_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in valid_loader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            model.init_hidden()\n",
    "            predict_y = model(X)\n",
    "            predict_label = torch.max(predict_y, 1)[1]\n",
    "            correct += predict_label.eq(Y.view_as(predict_label)).sum().item()\n",
    "    return correct/len(valid_loader.dataset)  # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb122f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def objective(trial):\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # RNNの層数\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 9)\n",
    "\n",
    "    # hidden_size\n",
    "    hidden_size = int(trial.suggest_discrete_uniform('hidden_size', 10, 150, 10))\n",
    "\n",
    "    # batch_size\n",
    "    batch_size = trial.suggest_int('batch_size', 8, 256)\n",
    "\n",
    "    # lr\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "\n",
    "    # dataloaderの定義\n",
    "    train_dataset2 = torch.utils.data.TensorDataset(X_train_long, Y_train_long)\n",
    "    train_dataloader2 = torch.utils.data.DataLoader(train_dataset2, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    valid_dataset2 = torch.utils.data.TensorDataset(X_valid_long, Y_valid_long)\n",
    "    valid_dataloader2 = torch.utils.data.DataLoader(valid_dataset2, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "    # モデルの作成\n",
    "    model = biRNN(vocab_size, 300, hidden_size, 4, batch_size, num_layers)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "    for epoch in range(20):\n",
    "        train(model, device, train_dataloader2, optimizer)\n",
    "        accuracy = valid(model, device, valid_dataloader2)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01eeee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-01 13:23:59,799]\u001b[0m A new study created in memory with name: no-name-9e2d9ae9-ae41-43d5-9559-6148569923c7\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:24:31,991]\u001b[0m Trial 0 finished with value: 0.6998502994011976 and parameters: {'num_layers': 7, 'hidden_size': 70.0, 'batch_size': 152, 'lr': 6.632403040709418e-05}. Best is trial 0 with value: 0.6998502994011976.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:24:42,806]\u001b[0m Trial 1 finished with value: 0.39520958083832336 and parameters: {'num_layers': 4, 'hidden_size': 70.0, 'batch_size': 252, 'lr': 0.046926316899077676}. Best is trial 0 with value: 0.6998502994011976.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:25:27,269]\u001b[0m Trial 2 finished with value: 0.3772455089820359 and parameters: {'num_layers': 8, 'hidden_size': 150.0, 'batch_size': 116, 'lr': 0.007877259985912046}. Best is trial 0 with value: 0.6998502994011976.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:25:37,409]\u001b[0m Trial 3 finished with value: 0.7028443113772455 and parameters: {'num_layers': 2, 'hidden_size': 70.0, 'batch_size': 137, 'lr': 0.006499757405437935}. Best is trial 3 with value: 0.7028443113772455.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:26:13,226]\u001b[0m Trial 4 finished with value: 0.7597305389221557 and parameters: {'num_layers': 3, 'hidden_size': 110.0, 'batch_size': 52, 'lr': 0.00047202545985723085}. Best is trial 4 with value: 0.7597305389221557.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:26:24,180]\u001b[0m Trial 5 finished with value: 0.5561377245508982 and parameters: {'num_layers': 1, 'hidden_size': 20.0, 'batch_size': 110, 'lr': 0.00016178931818992812}. Best is trial 4 with value: 0.7597305389221557.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:28:45,608]\u001b[0m Trial 6 finished with value: 0.8143712574850299 and parameters: {'num_layers': 9, 'hidden_size': 30.0, 'batch_size': 41, 'lr': 0.0008503539563632567}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:29:31,895]\u001b[0m Trial 7 finished with value: 0.75 and parameters: {'num_layers': 8, 'hidden_size': 80.0, 'batch_size': 94, 'lr': 6.662965362527343e-05}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:29:50,576]\u001b[0m Trial 8 finished with value: 0.38922155688622756 and parameters: {'num_layers': 6, 'hidden_size': 90.0, 'batch_size': 206, 'lr': 0.07664927351557237}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:30:05,172]\u001b[0m Trial 9 finished with value: 0.40494011976047906 and parameters: {'num_layers': 6, 'hidden_size': 40.0, 'batch_size': 248, 'lr': 1.0901021470340232e-05}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:37:59,691]\u001b[0m Trial 10 finished with value: 0.594311377245509 and parameters: {'num_layers': 9, 'hidden_size': 10.0, 'batch_size': 12, 'lr': 0.0018911080529983785}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:39:12,216]\u001b[0m Trial 11 finished with value: 0.7919161676646707 and parameters: {'num_layers': 4, 'hidden_size': 130.0, 'batch_size': 32, 'lr': 0.0005972968020160033}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:41:48,162]\u001b[0m Trial 12 finished with value: 0.562125748502994 and parameters: {'num_layers': 4, 'hidden_size': 150.0, 'batch_size': 18, 'lr': 0.0012780373157463313}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:42:34,870]\u001b[0m Trial 13 finished with value: 0.8046407185628742 and parameters: {'num_layers': 5, 'hidden_size': 120.0, 'batch_size': 62, 'lr': 0.00031741247354601755}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:43:18,734]\u001b[0m Trial 14 finished with value: 0.6856287425149701 and parameters: {'num_layers': 6, 'hidden_size': 40.0, 'batch_size': 73, 'lr': 0.003988020815808141}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:44:42,208]\u001b[0m Trial 15 finished with value: 0.8053892215568862 and parameters: {'num_layers': 9, 'hidden_size': 110.0, 'batch_size': 62, 'lr': 0.00019825691778367976}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:45:14,758]\u001b[0m Trial 16 finished with value: 0.6497005988023952 and parameters: {'num_layers': 9, 'hidden_size': 100.0, 'batch_size': 168, 'lr': 2.2646664992520098e-05}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:46:02,614]\u001b[0m Trial 17 finished with value: 0.7799401197604791 and parameters: {'num_layers': 8, 'hidden_size': 50.0, 'batch_size': 88, 'lr': 0.00013244114257096923}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:47:41,199]\u001b[0m Trial 18 finished with value: 0.4124251497005988 and parameters: {'num_layers': 9, 'hidden_size': 130.0, 'batch_size': 49, 'lr': 0.0154121547956897}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:49:52,611]\u001b[0m Trial 19 finished with value: 0.5868263473053892 and parameters: {'num_layers': 7, 'hidden_size': 30.0, 'batch_size': 35, 'lr': 0.002576801006470127}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:50:15,272]\u001b[0m Trial 20 finished with value: 0.7926646706586826 and parameters: {'num_layers': 7, 'hidden_size': 50.0, 'batch_size': 185, 'lr': 0.0009587115739462155}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:51:03,883]\u001b[0m Trial 21 finished with value: 0.8038922155688623 and parameters: {'num_layers': 5, 'hidden_size': 120.0, 'batch_size': 63, 'lr': 0.00033762612620123587}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:51:40,844]\u001b[0m Trial 22 finished with value: 0.7612275449101796 and parameters: {'num_layers': 5, 'hidden_size': 100.0, 'batch_size': 79, 'lr': 0.00023234772173040376}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:53:17,019]\u001b[0m Trial 23 finished with value: 0.7971556886227545 and parameters: {'num_layers': 8, 'hidden_size': 120.0, 'batch_size': 45, 'lr': 7.077747866031996e-05}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:54:08,099]\u001b[0m Trial 24 finished with value: 0.7470059880239521 and parameters: {'num_layers': 9, 'hidden_size': 140.0, 'batch_size': 111, 'lr': 0.0007890532627729173}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:54:37,439]\u001b[0m Trial 25 finished with value: 0.7859281437125748 and parameters: {'num_layers': 3, 'hidden_size': 110.0, 'batch_size': 66, 'lr': 0.0001307655891449678}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 13:56:46,071]\u001b[0m Trial 26 finished with value: 0.7567365269461078 and parameters: {'num_layers': 7, 'hidden_size': 90.0, 'batch_size': 28, 'lr': 3.233956002519915e-05}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:04:50,560]\u001b[0m Trial 27 finished with value: 0.7477544910179641 and parameters: {'num_layers': 6, 'hidden_size': 130.0, 'batch_size': 9, 'lr': 0.0003467399721457633}. Best is trial 6 with value: 0.8143712574850299.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:05:21,201]\u001b[0m Trial 28 finished with value: 0.8158682634730539 and parameters: {'num_layers': 5, 'hidden_size': 110.0, 'batch_size': 102, 'lr': 0.00022770005559626027}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:05:52,916]\u001b[0m Trial 29 finished with value: 0.687874251497006 and parameters: {'num_layers': 8, 'hidden_size': 60.0, 'batch_size': 139, 'lr': 3.3751659597271275e-05}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:06:13,676]\u001b[0m Trial 30 finished with value: 0.7687125748502994 and parameters: {'num_layers': 3, 'hidden_size': 80.0, 'batch_size': 95, 'lr': 9.311314552614433e-05}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:07:00,364]\u001b[0m Trial 31 finished with value: 0.812125748502994 and parameters: {'num_layers': 5, 'hidden_size': 110.0, 'batch_size': 65, 'lr': 0.00021782797557561625}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:07:26,288]\u001b[0m Trial 32 finished with value: 0.7874251497005988 and parameters: {'num_layers': 4, 'hidden_size': 100.0, 'batch_size': 100, 'lr': 0.00021548152817807724}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:07:59,125]\u001b[0m Trial 33 finished with value: 0.7065868263473054 and parameters: {'num_layers': 7, 'hidden_size': 110.0, 'batch_size': 125, 'lr': 0.00167986796419048}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:08:59,203]\u001b[0m Trial 34 finished with value: 0.7582335329341318 and parameters: {'num_layers': 5, 'hidden_size': 90.0, 'batch_size': 47, 'lr': 0.0005398782641593381}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:09:34,861]\u001b[0m Trial 35 finished with value: 0.750748502994012 and parameters: {'num_layers': 5, 'hidden_size': 70.0, 'batch_size': 81, 'lr': 4.528116652927749e-05}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:09:55,501]\u001b[0m Trial 36 finished with value: 0.3570359281437126 and parameters: {'num_layers': 4, 'hidden_size': 140.0, 'batch_size': 150, 'lr': 0.012246903281320469}. Best is trial 28 with value: 0.8158682634730539.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:10:27,056]\u001b[0m Trial 37 finished with value: 0.8173652694610778 and parameters: {'num_layers': 2, 'hidden_size': 80.0, 'batch_size': 57, 'lr': 0.00019348150284685184}. Best is trial 37 with value: 0.8173652694610778.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:10:37,080]\u001b[0m Trial 38 finished with value: 0.4491017964071856 and parameters: {'num_layers': 1, 'hidden_size': 10.0, 'batch_size': 123, 'lr': 0.00010019365976152751}. Best is trial 37 with value: 0.8173652694610778.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:10:55,604]\u001b[0m Trial 39 finished with value: 0.6976047904191617 and parameters: {'num_layers': 2, 'hidden_size': 60.0, 'batch_size': 103, 'lr': 0.003735982107459437}. Best is trial 37 with value: 0.8173652694610778.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:12:01,123]\u001b[0m Trial 40 finished with value: 0.7088323353293413 and parameters: {'num_layers': 2, 'hidden_size': 20.0, 'batch_size': 24, 'lr': 0.0006626838025040199}. Best is trial 37 with value: 0.8173652694610778.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:12:35,272]\u001b[0m Trial 41 finished with value: 0.8323353293413174 and parameters: {'num_layers': 2, 'hidden_size': 110.0, 'batch_size': 55, 'lr': 0.00027789396030742676}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:13:17,501]\u001b[0m Trial 42 finished with value: 0.7919161676646707 and parameters: {'num_layers': 2, 'hidden_size': 100.0, 'batch_size': 40, 'lr': 0.000452636856875702}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:13:59,500]\u001b[0m Trial 43 finished with value: 0.7470059880239521 and parameters: {'num_layers': 3, 'hidden_size': 70.0, 'batch_size': 56, 'lr': 0.001089682615207914}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:14:14,343]\u001b[0m Trial 44 finished with value: 0.7776946107784432 and parameters: {'num_layers': 1, 'hidden_size': 90.0, 'batch_size': 83, 'lr': 0.00026951713792524196}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:14:32,068]\u001b[0m Trial 45 finished with value: 0.7784431137724551 and parameters: {'num_layers': 1, 'hidden_size': 80.0, 'batch_size': 68, 'lr': 0.00015091354842784355}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:15:16,227]\u001b[0m Trial 46 finished with value: 0.7964071856287425 and parameters: {'num_layers': 3, 'hidden_size': 120.0, 'batch_size': 51, 'lr': 0.0003658929452927792}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:16:03,970]\u001b[0m Trial 47 finished with value: 0.7709580838323353 and parameters: {'num_layers': 6, 'hidden_size': 110.0, 'batch_size': 74, 'lr': 5.381463821726468e-05}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:18:24,687]\u001b[0m Trial 48 finished with value: 0.780688622754491 and parameters: {'num_layers': 4, 'hidden_size': 140.0, 'batch_size': 20, 'lr': 0.00010278992320265867}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n",
      "\u001b[32m[I 2022-08-01 14:18:34,708]\u001b[0m Trial 49 finished with value: 0.35778443113772457 and parameters: {'num_layers': 3, 'hidden_size': 30.0, 'batch_size': 229, 'lr': 1.1669772078948615e-05}. Best is trial 41 with value: 0.8323353293413174.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72105c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'num_layers': 2, 'hidden_size': 110.0, 'batch_size': 55, 'lr': 0.00027789396030742676}\n",
      "best value: 0.8323353293413174\n"
     ]
    }
   ],
   "source": [
    "print(f'best params: {study.best_params}')\n",
    "print(f'best value: {study.best_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5922c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
